#!/usr/bin/env sh
# Store and sync GitHub issues as local Git refs
#
# Available commands: ${ALL_FUNCS}
#
# Usage: ${NAME} [<options>] command [<args>]
#
# Options:
#   -h      Show this screen.
#   -v      Show version.
#   -d      Enable xtrace debug logging.
#   -r      Print your current GitHub API rate limit to stderr.
#   -q      Quiet; don't print to stdout.
#
# Creates refs/issues/<remote>/<issue num> as Git refs. Each ref contains a
# tree containing a JSON file for the issue and JSON files for each comment.
# Changes to the issue and to any comments are stored as history on that ref.
#
# Requirements:
#
# * A POSIX environment (tested against Busybox v1.19.4)
# * curl (tested against 7.32.0)
# * jq <http://stedolan.github.io/jq/> (tested against 1.3)
# * Git (tested against 1.8.5.3)
#
# Authentication credentials are read from a ~/.netrc file with the following
# format. Generate the token on GitHub under Account Settings -> Applications.
# Restrict permissions on that file with ``chmod 600 ~/.netrc``!
#
#   machine api.github.com
#       login <username>
#       password <token>

export NAME=$(basename $0)
export ALL_FUNCS=$(awk 'BEGIN {ORS=" "} !/^_/ && /^[a-zA-Z0-9_]+\s*\(\)/ {
    sub(/\(\)$/, "", $1); print $1 }' $0 | sort)

VERSION='0.1.0'

export GH_URL=${GH_URL:-'https://api.github.com'}
GH_HEADERS='Accept: application/vnd.github.v3+json'
GH_RATE_LIMIT=0

export E_NO_COMMAND=41
export E_INCORRECT_ARGS=42
export E_COMMAND_NOT_FOUND=43
export E_GITHUB_ERROR=44
export E_REMOTE_NOT_GITHUB=45
export E_REMOTE_NOT_FOUND=46

_get_repo() {
    # Return the account name and the repo name based on a remote URL
    #
    # remote
    #   The name of a remote. Defaults to the first listed remote.

    local uri
    local remote="${1:-$(git remote | head -1)}"

    # FIXME: account for other URL styles (http, git, owned and not owned)
    # git://github.com/user/repo.git

    git remote show -n "${remote}" | awk '
    /Fetch URL/ {
        len = length($3)
        url_idx = index($3, "@")
        account_idx = index($3, ":")
        repo_idx = index($3, "/")

        url = substr($3, url_idx + 1, account_idx - url_idx - 1)
        account = substr($3, account_idx + 1, repo_idx - account_idx - 1)
        repo = substr($3, repo_idx + 1, length($3) - repo_idx - 4)

        if (! url ~ /^github/) exit ENVIRON["E_REMOTE_NOT_GITHUB"]

        print account "/" repo
    }'

}

_commit() {
    # Write a commit object to Git
    #
    # - (stdin)
    #   The contents of the new object.
    # filename
    #   The filename to use in the tree.
    # ref
    #   Create or update this ref to point to the new object.
    # date
    #   A date to use for the author/committer date.
    # author
    #   The name to use as the author/committer name/email.
    # uri
    #   The URI the issue came from.
    #   Stored to allow checking for updates.
    # etag
    #   The etag returned from fetching the URI.
    #   Stored to allow conditional update checks.
    # message
    #   Commit message for the new object.
    # parent
    #   Optional parent object for the new commit.

    local filename="${1}"
    local ref="${2}"
    local date="${3}"
    local author="${4}"
    local uri="${5}"
    local etag="${6}"
    local message="${8}"
    local parent="${9}"
    local obj tree commit

    # These values are hard-coded so that a predictable SHA can be generated.
    export GIT_AUTHOR_NAME="${author}"
    export GIT_AUTHOR_EMAIL="${author}@example.com"
    export GIT_AUTHOR_DATE="${date}"
    export GIT_COMMITTER_NAME="${GIT_AUTHOR_NAME}"
    export GIT_COMMITTER_EMAIL="${GIT_AUTHOR_EMAIL}"
    export GIT_COMMITTER_DATE="${GIT_AUTHOR_DATE}"

    obj=$(git hash-object -w --stdin)
    tree=$(printf '100644 blob %s\t%s\n' "${obj}" "${filename}" | git mktree)
    commit=$(git commit-tree "${tree}" ${parent:+-p ${parent}} \
        -m "${message}")

    git update-ref "${ref}" "${commit}"
    git notes --ref issue add "${ref}" -m "${uri} ${etag}"
}

_process_issues() {
    # Add, update, or ignore unchanged GitHub issues
    #
    # - (stdin)
    #   GitHub issues as JSON objects, one per line.
    # uri
    #   The URI used to fetch the HTTP response.
    # etag
    #   The etag from the HTTP response.
    #
    # The HTTP response headers are written to a ref and each issue is written
    # to a ref. Then a link is created for the issue ref to the HTTP response
    # it came from so we can check GitHub for updates to an issue by resending
    # the same HTTP request.

    local uri="${1}"
    local etag="${2}"
    local line issue_no issue_date issue_user ref parent new_obj cur_obj

    # Disable stderr for the duration of the loop below.
    exec 3<&2 2>/dev/null

    # Loop over each issue to deterime if it is a new issue, a new version of
    # an existing issue, or an existing issue that has not been changed. (Since
    # we're getting whole groups of issues at a time each one isn't necessarily
    # a new version.)
    while read -r line; do
        printf '%s\n' "${line}" |\
        jq -r '.["number"],.["created_at"],.["user"]["login"]' |\
        xargs -n3 | while read -r issue_no issue_date issue_user; do
            ref="refs/issue/${issue_no}"
            parent=$(git rev-parse --verify "${ref}")

            # Short-circuit if the ref exists and is the same as the new one.
            if [ -n "${parent}" ]; then
                new_obj=$(printf '%s\n' "${line}" | jq . |\
                    git hash-object --stdin)
                cur_obj=$(printf '%s\n' "${ref}:issue.json" |\
                    git cat-file --batch-check='%(objectname)')

                if [ "${new_obj}" == "${cur_obj}" ]; then
                    printf 'Skipped issue %s\n' "${ref}"
                fi
            else
                # Create or update the issue to Git.
                # Run the JSON back through jq so the file written to Git is pretty.
                printf '%s\n' "${line}" | jq . |\
                    _commit "issue.json" \
                        "${ref}" \
                        "${issue_date}" \
                        "${issue_user}" \
                        "${uri}"\
                        "${etag}"\
                        "Issue #${issue_no}"\
                        "${parent}"

                [ -n "${parent}" ] && printf "Updated " || printf "Added "
                printf 'issue %s\n' "${ref}"
            fi

        done
    done

    # Restore stderr.
    exec 2<&3 3>&-
}

_process_response() {
    # Process an HTTP reponse splitting headers from the body
    #
    # - (stdin)
    #   The full HTTP response including headers.
    #
    # Returns the HTTP headers as tab-delimited key -> val pairs followed by
    # the untouched HTTP body. Desired headers are passed as positional
    # arguments. If no positional arguments are passed then no headers are
    # output.
    #
    # Some headers are reformatted into forms easier to process with shell
    # tools. If the server response is not 200 then no processing is done and
    # nothing is returned.

    local status hdr val etag

    read -r status
    status="${status%}"
    status="${status#HTTP* }"

    # If the response is a 304 we already have the latest versions of the
    # issues in this group stored.
    case $status in
        200*) : ;;
        *) printf '%s\n' "${status}" 1>&2; return ${E_GITHUB_ERROR};;
    esac

    while IFS=": " read -r hdr val; do
        # Headers stop at the first blank line.
        # Why oh why do headers from GitHub have Windows line endings?
        [ "$hdr" == "" ] && break
        val="${val%}"

        # Process or format certain headers so they're easier to work with.
        case "$hdr" in
            # Remote quotes from the etag header.
            ETag) val="${val#\"}"; val="${val%\"}";;

            # Output last page number only.
            Link) val="${val##*page=}"; val="${val%>*}";;

            # Update the GitHub rate limit counter.
            X-RateLimit-Remaining) GH_RATE_LIMIT="$val";;
        esac

        case "$hdr" in
            # Output the requested headers.
            $1) printf '%s\t%s\n' "${hdr}" "${val}";;
            $2) printf '%s\t%s\n' "${hdr}" "${val}";;
            $3) printf '%s\t%s\n' "${hdr}" "${val}";;
            $4) printf '%s\t%s\n' "${hdr}" "${val}";;
            $5) printf '%s\t%s\n' "${hdr}" "${val}";;
            $6) printf '%s\t%s\n' "${hdr}" "${val}";;
            $7) printf '%s\t%s\n' "${hdr}" "${val}";;
            $8) printf '%s\t%s\n' "${hdr}" "${val}";;
            $9) printf '%s\t%s\n' "${hdr}" "${val}";;
        esac
    done

    # Output the response body.
    cat
}

_get_issue_urls() {
    # Assemble a list of URLs for all available issues
    #
    # remote
    #   The name of the remote to sync with
    #
    # Makes an HTTP call to fetch the Link header to determine the total number
    # of issue pages then extrapolates that into a list of URLs. If the URL has
    # been fetched previously, pair it with the saved etag.

    # FIXME: wrap the following curl call in a check for a 200 response code.
    # FIXME: the links header is not returned if there is less than one page.

    local remote="${1}"
    local path="repos/$(_get_repo "${remote}")/issues"
    local qs='state=all&per_page=100&page=%s'
    local uri="${GH_URL}/${path}?${qs}"
    local headers t_links last_pg

    # Make a HEAD request so we can get the last page number.
    last_pg=$(curl -nsSI -H "${GH_HEADERS}" "$(printf "${uri}")" |\
        _process_response 'Link')

    [ $? -ne 0 ] && return $?
    last_pg="${last_pg#Link	*}"
    last_pg="${last_pg:=1}"

    # Compile a list of all issue notes that point to an issue branch head.
    # (We only care about notes for the latest issue versions.)
    git show-ref | awk '
    BEGIN {
        # Map of previous HTTP responses to issue refs.
        cmd = "git notes --ref issue"
        while ((cmd | getline) > 0) responses[$2] = $1
        close(cmd)
    }

    # Save ref if we have a stored HTTP response for it.
    $2 ~ /refs\/issue/ {
        if ($1 in responses) requests[responses[$1]] = 1
    }

    END {
        for (i in requests) print i
    }
    ' | git cat-file --batch |\
        awk -v last_pg=${last_pg} -v issues_url="${uri}" '
    /^http/ {
        urls[$1] = $2
    }

    END {
        for (i = 1; i < last_pg; i += 1) {
            url = sprintf(issues_url, i)
            urls[url] = urls[url]
        }

        for (i in urls) print i, urls[i]
    }
    ' | sort -u -n -k1.80
}

sync() {
    # Grab all issues from GitHub and write or update the local store
    #
    # remote
    #   The name of the remote to sync with
    #
    # HTTP requests are done conditionally. If we have a valid etag from the
    # last fetch GitHub won't count that request against your rate limit.

    local url etag
    local remote="${1}"

    _get_issue_urls "${remote}" | while read -r url etag; do
        if [ -n "${etag}" ]; then
            etag="-H 'If-None-Match: ${etag}'"
        fi

        curl -nsSi "${etag}" -H "${GH_HEADERS}" "${url}" |\
            _process_response "${url}"
    done
}

list() {
    # List all issue numbers that have been stored locally

    git show-ref |\
        awk -F/ '/refs\/issue/ { print "refs/issue/" $3 ":issue.json" }' |\
        git cat-file --batch | awk '!/^[a-z0-9]+.*blob/ { print }' |\
        jq -r '.["number"],.["title"]' | sort -n
}

show() {
    # Output an issue
    #
    # issue
    #   An issue number to fetch and display.

    local issue="${1}"

    printf 'refs/issue/%s:issue.json' "${issue}" | git cat-file --batch |\
        awk 'NR != 1 { print }' |\
        jq -r '.["number"],.["title"],.["user"]["login"],.["state"],.["milestone"]["title"],.["labels"][]["name"],.["body"]'
}

open() {
    # Output issues marked as open

    git show-ref |\
        awk -F/ '/refs\/issue/ { print "refs/issue/" $3 ":issue.json" }' |\
        git cat-file --batch | awk '!/^[a-z0-9]+.*blob/ { print }' |\
        jq -r 'select(.["state"] == "open") | .["number"]' | sort -n
}

_helptext() {
    # Extract lines of contiguous comment characters as inline help text
    #
    # Indentation will be ignored. The first line of the match will be ignored
    # (this is to ignore the she-bang of a file or the function name.
    # Exits upon encountering the first blank line.
    #
    # Exported environment variables can be used for string interpolation in
    # the extracted text.

    # FIXME: gensub is not Posix (present in busybox & bsd but not solaris(?))
    awk 'NR != 1 && /^\s*#/ { while(match($0,"[$]{[^}]*}")) {
            var=substr($0,RSTART+2,RLENGTH -3)
            gsub("[$]{"var"}",ENVIRON[var])
            }; print gensub(/^\s*#\s?/, "", $0) }
        !NF { exit }' "$@"
}

help() {
    # Output the help text for a command
    #
    # Usage: ${NAME} help commandname

    if [ $# -gt 0 ]; then
        awk -v fname="^$1" '$0 ~ fname, /^}/ { print }' $0 | _helptext
    else
        _helptext $0
    fi
}

_main() {
    # Parse command line options and call the given command

    local cmd opt OPTARG OPTIND
    local quiet=0
    local show_rate_limit=0

    while getopts l:qrvdh opt; do
        case $opt in
        q)  quiet=1;;
        r)  show_rate_limit=1;;
        v)  printf 'Version: %s\n' $VERSION
            exit;;
        d)  set -x;;
        h)  help
            printf '\n'
            exit;;
        \?) help
            exit 3;;
        esac
    done
    shift $(($OPTIND - 1))

    if [ -z "$1" ] ; then
        printf 'No command given\n\n'
        help
        exit ${E_NO_COMMAND}
    fi

    local cmd="${1}" && shift

    # Run the command
    if [ $quiet -eq 1 ]; then
        { ${cmd} "$@"; } > /dev/null
    else
        ${cmd} "$@"
    fi

    case $? in
    0)      :
            ;;
    127)    help
            exit $(( E_COMMAND_NOT_FOUND ));;
    *)      exit $?;;
    esac

    # Output the rate limit
    if [ $show_rate_limit -eq 1 ]; then
        printf 'Remaining GitHub requests: %s\n' "${GH_RATE_LIMIT:-'Unknown'}"
    fi
}

_main "$@"
