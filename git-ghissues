#!/usr/bin/env sh
# Store and sync GitHub issues as local Git refs
#
# Available commands: ${ALL_FUNCS}
#
# Usage: ${NAME} [<options>] command [<args>]
#
# Options:
#   -h      Show this screen.
#   -v      Show version.
#   -d      Enable xtrace debug logging.
#   -r      Print your current GitHub API rate limit to stderr.
#   -q      Quiet; don't print to stdout.
#
# Creates refs/issues/<remote>/<issue num> as Git refs. Each ref contains a
# tree containing a JSON file for the issue and JSON files for each comment.
# Changes to the issue and to any comments are stored as history on that ref.
#
# Requirements:
#
# * A POSIX environment (tested against Busybox v1.19.4)
# * curl (tested against 7.32.0)
# * jq <http://stedolan.github.io/jq/> (tested against 1.3)
# * Git (tested against 1.8.5.3)
#
# Authentication credentials are read from a ~/.netrc file with the following
# format. Generate the token on GitHub under Account Settings -> Applications.
# Restrict permissions on that file with ``chmod 600 ~/.netrc``!
#
#   machine api.github.com
#       login <username>
#       password <token>

export NAME=$(basename $0)
export ALL_FUNCS=$(awk 'BEGIN {ORS=" "} !/^_/ && /^[a-zA-Z0-9_]+\s*\(\)/ {
    sub(/\(\)$/, "", $1); print $1 }' $0 | sort)

VERSION='0.1.0'

GH_URL=${GH_URL:-'https://api.github.com'}
GH_HEADERS='Accept: application/vnd.github.v3+json'
GH_ISSUES='%s/repos/%s/%s?state=all&per_page=100&page=%%s'
GH_RATE_LIMIT=0

export E_NO_COMMAND=41
export E_INCORRECT_ARGS=42
export E_COMMAND_NOT_FOUND=43
export E_GITHUB_ERROR=44
export E_REMOTE_NOT_GITHUB=45
export E_REMOTE_NOT_FOUND=46

_get_repo() {
    # Return the account name and the repo name based on a remote URL
    #
    # remote
    #   The name of a remote. Defaults to the first listed remote.

    local uri
    local remote="${1:-$(git remote | head -1)}"

    # FIXME: account for other URL styles (http, git, owned and not owned)
    # git://github.com/user/repo.git

    git remote show -n "${remote}" | awk '
    /Fetch URL/ {
        len = length($3)
        url_idx = index($3, "@")
        account_idx = index($3, ":")
        repo_idx = index($3, "/")

        url = substr($3, url_idx + 1, account_idx - url_idx - 1)
        account = substr($3, account_idx + 1, repo_idx - account_idx - 1)
        repo = substr($3, repo_idx + 1, length($3) - repo_idx - 4)

        if (! url ~ /^github/) exit ENVIRON["E_REMOTE_NOT_GITHUB"]

        print account "/" repo
    }'

}

_commit() {
    # Write a commit object to Git
    #
    # - (stdin)
    #   The contents of the new object.
    # filename
    #   The filename to use in the tree.
    # ref
    #   Create or update this ref to point to the new object.
    # date
    #   A date to use for the author/committer date.
    # author
    #   The name to use as the author/committer name/email.
    # uri
    #   The URI the issue came from.
    #   Stored to allow checking for updates.
    # etag
    #   The etag returned from fetching the URI.
    #   Stored to allow conditional update checks.
    # message
    #   Commit message for the new object.
    # parent
    #   Optional parent object for the new commit.

    local filename="${1}"
    local ref="${2}"
    local date="${3}"
    local author="${4}"
    local uri="${5}"
    local etag="${6}"
    local message="${8}"
    local parent="${9}"
    local obj tree commit

    # These values are hard-coded so that a predictable SHA can be generated.
    export GIT_AUTHOR_NAME="${author}"
    export GIT_AUTHOR_EMAIL="${author}@ghissues.example.com"
    export GIT_AUTHOR_DATE="${date}"
    export GIT_COMMITTER_NAME="${GIT_AUTHOR_NAME}"
    export GIT_COMMITTER_EMAIL="${GIT_AUTHOR_EMAIL}"
    export GIT_COMMITTER_DATE="${GIT_AUTHOR_DATE}"

    obj=$(git hash-object -w --stdin)
    tree=$(printf '100644 blob %s\t%s\n' "${obj}" "${filename}" | git mktree)
    commit=$(git commit-tree "${tree}" ${parent:+-p ${parent}} \
        -m "${message}")

    git update-ref "${ref}" "${commit}"
    git notes --ref issues add "${ref}" -m "${uri} ${etag}"
}

_process_issues() {
    # Add, update, or ignore unchanged GitHub issues
    #
    # - (stdin)
    #   GitHub issues as JSON objects, one per line.
    # uri
    #   The URI used to fetch the HTTP response.
    # etag
    #   The etag from the HTTP response.
    #
    # The HTTP response headers are written to a ref and each issue is written
    # to a ref. Then a link is created for the issue ref to the HTTP response
    # it came from so we can check GitHub for updates to an issue by resending
    # the same HTTP request.

    local uri="${1}"
    local etag="${2}"
    local line issue_no issue_date issue_user ref parent new_obj cur_obj

    # Disable stderr for the duration of the loop below.
    exec 3<&2 2>/dev/null

    # Loop over each issue to deterime if it is a new issue, a new version of
    # an existing issue, or an existing issue that has not been changed. (Since
    # we're getting whole groups of issues at a time each one isn't necessarily
    # a new version.)
    while read -r line; do
        printf '%s\n' "${line}" |\
        jq -r '.["number"],.["created_at"],.["user"]["login"]' |\
        xargs -n3 | while read -r issue_no issue_date issue_user; do
            ref="refs/issue/${issue_no}"
            parent=$(git rev-parse --verify "${ref}")

            # Short-circuit if the ref exists and is the same as the new one.
            if [ -n "${parent}" ]; then
                new_obj=$(printf '%s\n' "${line}" | jq . |\
                    git hash-object --stdin)
                cur_obj=$(printf '%s\n' "${ref}:issue.json" |\
                    git cat-file --batch-check='%(objectname)')

                if [ "${new_obj}" == "${cur_obj}" ]; then
                    printf 'Skipped issue %s\n' "${ref}"
                fi
            else
                # Create or update the issue to Git.
                # Run the JSON back through jq so the file written to Git is pretty.
                printf '%s\n' "${line}" | jq . |\
                    _commit "issue.json" \
                        "${ref}" \
                        "${issue_date}" \
                        "${issue_user}" \
                        "${uri}"\
                        "${etag}"\
                        "Issue #${issue_no}"\
                        "${parent}"

                [ -n "${parent}" ] && printf "Updated " || printf "Added "
                printf 'issue %s\n' "${ref}"
            fi

        done
    done

    # Restore stderr.
    exec 2<&3 3>&-
}

_process_response() {
    # Process an HTTP reponse splitting headers from the body
    #
    # - (stdin)
    #   The full HTTP response including headers.
    #
    # Returns the HTTP headers as tab-delimited key -> val pairs followed by
    # the untouched HTTP body. Desired headers are passed as positional
    # arguments. If no positional arguments are passed then no headers are
    # output.
    #
    # Some headers are reformatted into forms easier to process with shell
    # tools. If the server response is not 200 then no processing is done and
    # nothing is returned.

    local status hdr val etag

    read -r status
    status="${status%}"
    status="${status#HTTP* }"

    # If the response is a 304 we already have the latest versions of the
    # issues in this group stored.
    case $status in
        200*) : ;;
        *) printf '%s\n' "${status}" 1>&2; return ${E_GITHUB_ERROR};;
    esac

    while IFS=": " read -r hdr val; do
        # Headers stop at the first blank line.
        # Why oh why do headers from GitHub have Windows line endings?
        [ "$hdr" == "" ] && break
        val="${val%}"

        # Process or format certain headers so they're easier to work with.
        case "$hdr" in
            # Remote quotes from the etag header.
            ETag) val="${val#\"}"; val="${val%\"}";;

            # Output last page number only.
            Link) val="${val##*page=}"; val="${val%>*}";;

            # Update the GitHub rate limit counter.
            X-RateLimit-Remaining) GH_RATE_LIMIT="$val";;
        esac

        case "$hdr" in
            # Output the requested headers.
            $1) printf '%s\n' "${val}";;
            $2) printf '%s\n' "${val}";;
            $3) printf '%s\n' "${val}";;
            $4) printf '%s\n' "${val}";;
            $5) printf '%s\n' "${val}";;
            $6) printf '%s\n' "${val}";;
            $7) printf '%s\n' "${val}";;
            $8) printf '%s\n' "${val}";;
            $9) printf '%s\n' "${val}";;
        esac
    done

    # Output the response body.
    cat
}

_get_all_urls() {
    # Assemble a list of URLs for all available issues or comments
    #
    # - (stdin)
    #   The output from ``git notes --ref <foo> list``
    # uri
    #   A URL pattern with the page number in printf format
    #
    # Makes an HTTP call to fetch the Link header to determine the total number
    # of pages then extrapolates that into a list of URLs. If the URL has been
    # fetched previously, pair it with the saved etag.

    local uri="${1}"
    local last_pg

    # Make a HEAD request so we can get the last page number.
    # FIXME: Check for a 200 response code.
    last_pg=$(curl -nsSI -H "${GH_HEADERS}" "$(printf "${uri}")" \
        | _process_response 'Link')

    [ $? -ne 0 ] && return $?
    last_pg="${last_pg#Link	*}"
    last_pg="${last_pg:=1}"

    # Get all URLs already processed and extrapolate any missing URLs.
    awk '{ print $1 }' \
        | git cat-file --batch='%(rest)'\
        | awk -v last_pg="${last_pg}" -v issues_uri="${uri}" '
            NF { urls[$1] = $2 }
            END {
                for (i = 1; i <= last_pg; i += 1) {
                    url = sprintf(issues_uri, i)
                    urls[url] = urls[url]
                }

                for (i in urls) print i, urls[i]
            }' \
        | sort -n -k1.80
}

_get_issues_urls() {
    # Return all issues URLs & last known etag
    #
    # remote
    #   The name of the remote to sync with

    local repo=$(_get_repo "$1")
    local uri=$(printf ${GH_ISSUES} "${GH_URL}" "${repo}" "issues")

    git notes --ref issues list | _get_all_urls "${uri}"
}

_get_issue_refspec() {
    # Format a refspec for the issue.json file for each SHA
    #
    # - (stdin) one SHA per line

    while read -r sha; do
        printf '%s:issue.json\n' "$sha"
    done
}

_get_issue_json() {
    # Retrieve the contents of refspec
    #
    # - (stdin) one refspec per line

    _get_issue_refspec \
        | git cat-file --batch='%(rest)'
}

_get_comments_urls() {
    # Returns all comment URLs & last known etag
    #
    # remote
    #   The name of the remote to sync with

    local repo=$(_get_repo "$1")
    local uri=$(printf ${GH_ISSUES} "${GH_URL}" "${repo}" "issues/comments")

    git notes --ref comments list | _get_all_urls "${uri}"
}

sync() {
    # Grab all issues from GitHub and write or update the local store
    #
    # remote
    #   The name of the remote to sync with
    #
    # HTTP requests are done conditionally. If we have a valid etag from the
    # last fetch GitHub won't count that request against your rate limit.

    local curl_cmd uri req_etag resp_etag
    local remote="$1"

    _get_issues_urls "${remote}" | while read -r uri req_etag ; do
        if [ -n "${req_etag}" ]; then
            req_etag="-H 'If-None-Match: ${req_etag}'"
        fi

        curl_cmd=$(printf 'curl -nsSi %s -H '\''%s'\'' %s' \
            "${req_etag}" "${GH_HEADERS}" "${uri}")

        eval "${curl_cmd}" \
            | _process_response 'ETag' \
            | while read -r resp_etag ; do
                # Reformat the issues as one issue per line so we can reason
                # about them individually with regular shell tools.
                jq -c '.[]' | _process_issues "${uri}" "${resp_etag}"
            done
    done
}

list() {
    # List all issue numbers that have been stored locally

    git notes --ref issue list \
        | awk '{ print $2 }' \
        | _get_issue_json \
        | jq -r '.["number"],.["title"]' \
        | awk 'NR % 2 != 0 { printf($0) } NR % 2 == 0 { print " " $0 }' \
        | sort -rn
}

show() {
    # Output an issue
    #
    # issue
    #   An issue number to fetch and display.

    local issue="${1}"
    local sha="$(git rev-parse refs/issues/${issue})"

    printf '%s\n' "$sha" \
        | _get_issue_json \
        | jq -r '.["number"],.["title"],.["user"]["login"],.["state"],.["milestone"]["title"],.["labels"][]["name"],.["body"]'
}

open() {
    # Output issues marked as open

    git notes --ref issue list \
        | awk '{ print $2 }' \
        | _get_issue_json \
        | jq -r 'select(.["state"] == "open") | .["number"]' \
        | sort -n
}

_helptext() {
    # Extract lines of contiguous comment characters as inline help text
    #
    # Indentation will be ignored. The first line of the match will be ignored
    # (this is to ignore the she-bang of a file or the function name.
    # Exits upon encountering the first blank line.
    #
    # Exported environment variables can be used for string interpolation in
    # the extracted text.

    # FIXME: gensub is not Posix (present in busybox & bsd but not solaris(?))
    awk 'NR != 1 && /^\s*#/ { while(match($0,"[$]{[^}]*}")) {
            var=substr($0,RSTART+2,RLENGTH -3)
            gsub("[$]{"var"}",ENVIRON[var])
            }; print gensub(/^\s*#\s?/, "", $0) }
        !NF { exit }' "$@"
}

help() {
    # Output the help text for a command
    #
    # Usage: ${NAME} help commandname

    if [ $# -gt 0 ]; then
        awk -v fname="^$1" '$0 ~ fname, /^}/ { print }' $0 | _helptext
    else
        _helptext $0
    fi
}

_main() {
    # Parse command line options and call the given command

    local cmd opt OPTARG OPTIND
    local quiet=0
    local show_rate_limit=0

    while getopts l:qrvdh opt; do
        case $opt in
        q)  quiet=1;;
        r)  show_rate_limit=1;;
        v)  printf 'Version: %s\n' $VERSION
            exit;;
        d)  set -x;;
        h)  help
            printf '\n'
            exit;;
        \?) help
            exit 3;;
        esac
    done
    shift $(($OPTIND - 1))

    if [ -z "$1" ] ; then
        printf 'No command given\n\n'
        help
        exit ${E_NO_COMMAND}
    fi

    local cmd="${1}" && shift

    # Run the command
    if [ $quiet -eq 1 ]; then
        { ${cmd} "$@"; } > /dev/null
    else
        ${cmd} "$@"
    fi

    case $? in
    0)      :
            ;;
    127)    help
            exit $(( E_COMMAND_NOT_FOUND ));;
    *)      exit $?;;
    esac

    # Output the rate limit
    if [ $show_rate_limit -eq 1 ]; then
        printf 'Remaining GitHub requests: %s\n' "${GH_RATE_LIMIT:-'Unknown'}"
    fi
}

_main "$@"
